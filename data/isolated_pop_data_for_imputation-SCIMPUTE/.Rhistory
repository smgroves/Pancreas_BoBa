install.packages(tidyverse,repos = 'https://cran.us.r-project.org')
install.packages("tidyverse", repos = 'https://cran.us.r-project.org')
install.packages("drc")
install.packages(c("caTools","kriging","lattice","plotrix","compiler","truncnorm","braidrm"))
install.packages(c("caTools", "kriging", "lattice", "plotrix", "compiler", "truncnorm", "braidrm"))
install.packages(c("caTools", "kriging", "lattice", "plotrix", "compiler", "truncnorm", "braidrm"))
install.packages(c("caTools", "kriging", "lattice", "plotrix", "compiler", "truncnorm", "braidrm"))
install.packages(c("caTools", "kriging", "lattice", "plotrix", "compiler", "truncnorm", "braidrm"))
install.packages(c("braidrm"))
install.packages(c("caTools"))
install.packages(c("kriging"))
install.packages(c("lattice"))
install.packages(c("plotrix"))
install.packages(c("compiler"))
library(compiler)
install.packages(c("truncnorm"))
library(drc)
library(caTools)
library(kriging)
library(lattice)
# library(reshape2)
library(plotrix)
library(compiler)
library(truncnorm)
library(braidrm)
install.packages("drc")
library(braidrm)
install.packages(braidrm)
install.packages("braidrm")
install.packages(c("caTools","kriging","lattice","reshape2","plotrix","truncnorm"))
require(ggplot2)
#- Prepare dataset containing single drug and combination data ----------------------
#- define concentration vector of drug A
c.drug.A = seq(1,100,1)
#- define concentration vector of drug A
c.drug.B = seq(1,100,1)
#- setup dataset
dummy = NULL
df    = NULL
for(i in 1:length(unique(c.drug.A))){
dummy = cbind(c.drug.A[i],c.drug.B)
df = rbind(df,dummy)
}
colnames(df) = c("DRUG_A","DRUG_B")
df = as.data.frame(df)
df
LA_GPDI_EC50 = function(C_A,C_B,
parms){
Emax_A = parms["Emax_A"]
EC50_A = parms["EC50_A"]
H_A    = parms["H_A"]
Emax_B = parms["Emax_B"]
EC50_B = parms["EC50_B"]
H_B    = parms["H_B"]
Int_AB    = parms["Int_AB"]
Int_BA    = parms["Int_BA"]
EC50_Int_AB    = parms["EC50_Int_AB"]
EC50_Int_BA    = parms["EC50_Int_BA"]
E_comb=rep(0,length(C_A))
for(i in 1:length(C_A)){
if(C_A[i] == 0 & C_B[i] == 0){E_comb[i]=0}else{
E_comb[i]=optim(0.0001,
fn=function(E){
abs((C_A[i] / (EC50_A * (1 + C_B[i]/(EC50_Int_AB + C_B[i]) * Int_AB) * ((E/(Emax_A-E)) ^ (1/H_A))) +
C_B[i] / (EC50_B * (1 + C_A[i]/(EC50_Int_BA + C_A[i]) * Int_BA) * ((E/(Emax_B-E)) ^ (1/H_B))) - 1 ))},
lower=0,
upper=1,
method="Brent",
control=list(trace=F,
reltol=1e-30))$par
}}
return(E_comb)
}
parset = list(
"LA" =
c("Emax_A" = 1,
"EC50_A" = 50,
"H_A"    = 4,
"Emax_B" = 1,
"EC50_B" = 50,
"H_B"    = 4,
"Int_AB"  = 0,
"Int_BA"  = 0,
"EC50_Int_AB" = 25,
"EC50_Int_BA" = 25))
dummy = NULL
for (i in 1:length(parset)){
df$E = LA_GPDI_EC50(df$DRUG_A,df$DRUG_B,parms=parset[[i]])
df$GROUP = names(parset[i])
dummy = rbind(dummy,df)
}
dummy$GR
df$E
parms=parset[[i]]
C_A=df$DRUG_A
C_B = df$DRUG_B
Emax_A = parms["Emax_A"]
EC50_A = parms["EC50_A"]
H_A    = parms["H_A"]
Emax_B = parms["Emax_B"]
EC50_B = parms["EC50_B"]
H_B    = parms["H_B"]
Int_AB    = parms["Int_AB"]
Int_BA    = parms["Int_BA"]
EC50_Int_AB    = parms["EC50_Int_AB"]
EC50_Int_BA    = parms["EC50_Int_BA"]
EC50_A
EC50_Int_AB
EC50_Int_BA
i=1
C_A[i]
C_B[i]
optim(0.0001,
fn=function(E){
abs((C_A[i] / (EC50_A * (1 + C_B[i]/(EC50_Int_AB + C_B[i]) * Int_AB) * ((E/(Emax_A-E)) ^ (1/H_A))) +
C_B[i] / (EC50_B * (1 + C_A[i]/(EC50_Int_BA + C_A[i]) * Int_BA) * ((E/(Emax_B-E)) ^ (1/H_B))) - 1 ))},
lower=0,
upper=1,
method="Brent",
control=list(trace=F,
reltol=1e-30))
optim(0.0001,
fn=function(E){
abs((C_A[i] / (EC50_A * (1 + C_B[i]/(EC50_Int_AB + C_B[i]) * Int_AB) * ((E/(Emax_A-E)) ^ (1/H_A))) +
C_B[i] / (EC50_B * (1 + C_A[i]/(EC50_Int_BA + C_A[i]) * Int_BA) * ((E/(Emax_B-E)) ^ (1/H_B))) - 1 ))},
lower=0,
upper=1,
method="Brent",
control=list(trace=F,
reltol=1e-10))
E_comb=rep(0,length(C_A))
for(i in 1:length(C_A)){
if(C_A[i] == 0 & C_B[i] == 0){E_comb[i]=0}else{
E_comb[i]=optim(0.0001,
fn=function(E){
abs((C_A[i] / (EC50_A * (1 + C_B[i]/(EC50_Int_AB + C_B[i]) * Int_AB) * ((E/(Emax_A-E)) ^ (1/H_A))) +
C_B[i] / (EC50_B * (1 + C_A[i]/(EC50_Int_BA + C_A[i]) * Int_BA) * ((E/(Emax_B-E)) ^ (1/H_B))) - 1 ))},
lower=0,
upper=1,
method="Brent",
control=list(trace=F,
reltol=1e-10))$convergence
}}
E_comb
sum(E_comb==1)
E_comb=rep(0,length(C_A))
for(i in 1:length(C_A)){
if(C_A[i] == 0 & C_B[i] == 0){E_comb[i]=0}else{
E_comb[i]=optim(0.0001,
fn=function(E){
abs((C_A[i] / (EC50_A * (1 + C_B[i]/(EC50_Int_AB + C_B[i]) * Int_AB) * ((E/(Emax_A-E)) ^ (1/H_A))) +
C_B[i] / (EC50_B * (1 + C_A[i]/(EC50_Int_BA + C_A[i]) * Int_BA) * ((E/(Emax_B-E)) ^ (1/H_B))) - 1 ))},
lower=0,
upper=1,
method="Brent",
control=list(trace=F,
reltol=1e-5))$convergence
}}
E_comb
E_comb==1
library(synergyfinder)
opt$PATH = '/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/'
opt <- NONE
opt <- data.frame()
opt$PATH = '/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/'
opt$PATH = '/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/'
opt
opt <- data.frame(c("OPT",/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53))
opt <- data.frame("OPT"='/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53'\)
opt <- data.frame("OPT"='/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/')
opt <- data.frame("PATH"='/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/')
opt
topdir <- opt$PATH
if(file.exists(topdir))
{
message(paste0('found ',topdir))
} else {
message(paste0('could not find ',topdir))
quit()
}
exptfile <- file.path(topdir,paste0(basename(topdir),'.xml'))
if(file.exists(exptfile))
{
message(paste0('found experiment file in ',topdir))
datadirs <- topdir
} else {
message(paste0('did not find experiment file in ',topdir))
datadirs <- list.dirs(topdir, recursive=FALSE)
}
# get paths to Segmentation directories
segdirs <- file.path(datadirs,'Segmentation')
topdir <- opt$PATH
if(file.exists(topdir))
{
message(paste0('found ',topdir))
} else {
message(paste0('could not find ',topdir))
quit()
}
topdir
topdir = opt$PATH[1]
if(file.exists(topdir))
{
message(paste0('found ',topdir))
} else {
message(paste0('could not find ',topdir))
quit()
}
topdir
topdir = '/mnt/vu1file/Data/CELLAVISTA/Sarah_Maddox/siRNA_lipid_optimization_3/final_DMS114_DMS53/'
if(file.exists(topdir))
{
message(paste0('found ',topdir))
} else {
message(paste0('could not find ',topdir))
quit()
}
exptfile <- file.path(topdir,paste0(basename(topdir),'.xml'))
if(file.exists(exptfile))
{
message(paste0('found experiment file in ',topdir))
datadirs <- topdir
} else {
message(paste0('did not find experiment file in ',topdir))
datadirs <- list.dirs(topdir, recursive=FALSE)
}
# get paths to Segmentation directories
segdirs <- file.path(datadirs,'Segmentation')
segdirs
# assemble all cell counts
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
#Assemble Data
d <- read.csv(paste0(topdir,'pyseg_args.csv'),as.is=TRUE)
dat <- data.frame(path=d$nuc_im_path)
dat$file.name <- sapply(dat$path, function(x) basename(toString(x)))
dat$expt.id <- sapply(dat$path, function(x) basename(dirname(dirname(toString(x)))))
dat$plate.id <- sapply(dat$path, function(x) basename(dirname(toString(x))))
temp <- as.data.frame(do.call(rbind,lapply(dat$file.name, function(x) as.character(parseCVFileName(x)))))
colnames(temp) <- c('file.name','image.time','image.number','row','col','well')
dat <- cbind(dat,temp[match(dat$file.name,temp$file.name),c('image.time','well')])
dat$cell.count <- cellcounts[match(dat$file.name,cellcounts$file_name),'cell_count']
dat$uid <- paste(dat$expt.id,dat$well,sep='_')
# need uid2 to identify each unique well per plate (time point) since multiple images per well
dat$uid2 <- paste(dat$expt.id,dat$plate.id,dat$well,sep='_')
# sum all counts in each unique well
temp <- aggregate(cell.count ~ uid2, data=dat, FUN=sum)
dat2 <- dat[!duplicated(dat$uid2),]
dat2$cell.count <- temp[match(dat2$uid2,temp$uid2),'cell.count']
dat2 <- dat2[,!colnames(dat2) %in% c('file.name','path')]
d <- dat2
d <- d[order(d$uid,d$image.time),]
d$time <- 0
d$time <- unlist(lapply(unique(d$uid), function(id) signif(difftime(d[d$uid==id,'image.time'],d[d$uid==id,'image.time'][1],units='hours'),3)))
d$uid2 <- NULL
rownames(d) <- NULL
#Save file
write.csv(d,file=paste0(fp),row.names=FALSE)
# assemble all cell counts
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
#Assemble Data
d <- read.csv(paste0(topdir,'pyseg_args.csv'),as.is=TRUE)
require(docopt)
require(diprate)
# assemble all cell counts
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
#Assemble Data
d <- read.csv(paste0(topdir,'pyseg_args.csv'),as.is=TRUE)
dat <- data.frame(path=d$nuc_im_path)
dat$file.name <- sapply(dat$path, function(x) basename(toString(x)))
dat$expt.id <- sapply(dat$path, function(x) basename(dirname(dirname(toString(x)))))
dat$plate.id <- sapply(dat$path, function(x) basename(dirname(toString(x))))
temp <- as.data.frame(do.call(rbind,lapply(dat$file.name, function(x) as.character(parseCVFileName(x)))))
colnames(temp) <- c('file.name','image.time','image.number','row','col','well')
dat <- cbind(dat,temp[match(dat$file.name,temp$file.name),c('image.time','well')])
dat$cell.count <- cellcounts[match(dat$file.name,cellcounts$file_name),'cell_count']
dat$uid <- paste(dat$expt.id,dat$well,sep='_')
# need uid2 to identify each unique well per plate (time point) since multiple images per well
dat$uid2 <- paste(dat$expt.id,dat$plate.id,dat$well,sep='_')
# sum all counts in each unique well
temp <- aggregate(cell.count ~ uid2, data=dat, FUN=sum)
dat2 <- dat[!duplicated(dat$uid2),]
dat2$cell.count <- temp[match(dat2$uid2,temp$uid2),'cell.count']
dat2 <- dat2[,!colnames(dat2) %in% c('file.name','path')]
d <- dat2
d <- d[order(d$uid,d$image.time),]
d$time <- 0
d$time <- unlist(lapply(unique(d$uid), function(id) signif(difftime(d[d$uid==id,'image.time'],d[d$uid==id,'image.time'][1],units='hours'),3)))
d$uid2 <- NULL
rownames(d) <- NULL
#Save file
write.csv(d,file=paste0(fp),row.names=FALSE)
# assemble all cell counts
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
#Assemble Data
d <- read.csv(paste0(topdir,'pyseg_args.csv'),as.is=TRUE)
dat <- data.frame(path=d$nuc_im_path)
dat$file.name <- sapply(dat$path, function(x) basename(toString(x)))
dat$expt.id <- sapply(dat$path, function(x) basename(dirname(dirname(toString(x)))))
dat$plate.id <- sapply(dat$path, function(x) basename(dirname(toString(x))))
temp <- as.data.frame(do.call(rbind,lapply(dat$file.name, function(x) as.character(parseCVFileName(x)))))
colnames(temp) <- c('file.name','image.time','image.number','row','col','well')
dat <- cbind(dat,temp[match(dat$file.name,temp$file.name),c('image.time','well')])
dat$cell.count <- cellcounts[match(dat$file.name,cellcounts$file_name),'cell_count']
dat$uid <- paste(dat$expt.id,dat$well,sep='_')
# need uid2 to identify each unique well per plate (time point) since multiple images per well
dat$uid2 <- paste(dat$expt.id,dat$plate.id,dat$well,sep='_')
# sum all counts in each unique well
temp <- aggregate(cell.count ~ uid2, data=dat, FUN=sum)
dat2 <- dat[!duplicated(dat$uid2),]
topdir
paste0(topdir,'cell_counts.csv')
fp = paste0(topdir,'cell_counts.csv')
fn = 'cell_counts.csv'
fn = 'all_cell_counts.csv'
fp = paste0(topdir,'all_cell_counts.csv')
# print('Segdirs:')
# print(segdirs)
# assemble all cell counts
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
toFile=TRUE
cellcounts <- do.call(rbind,lapply(segdirs, function(x) assemPlateData(x,toFile=toFile)))
#Assemble Data
d <- read.csv(paste0(topdir,'pyseg_args.csv'),as.is=TRUE)
dat <- data.frame(path=d$nuc_im_path)
dat$file.name <- sapply(dat$path, function(x) basename(toString(x)))
dat$expt.id <- sapply(dat$path, function(x) basename(dirname(dirname(toString(x)))))
dat$plate.id <- sapply(dat$path, function(x) basename(dirname(toString(x))))
temp <- as.data.frame(do.call(rbind,lapply(dat$file.name, function(x) as.character(parseCVFileName(x)))))
colnames(temp) <- c('file.name','image.time','image.number','row','col','well')
dat <- cbind(dat,temp[match(dat$file.name,temp$file.name),c('image.time','well')])
dat$cell.count <- cellcounts[match(dat$file.name,cellcounts$file_name),'cell_count']
dat$uid <- paste(dat$expt.id,dat$well,sep='_')
# need uid2 to identify each unique well per plate (time point) since multiple images per well
dat$uid2 <- paste(dat$expt.id,dat$plate.id,dat$well,sep='_')
# sum all counts in each unique well
temp <- aggregate(cell.count ~ uid2, data=dat, FUN=sum)
dat2 <- dat[!duplicated(dat$uid2),]
dat2$cell.count <- temp[match(dat2$uid2,temp$uid2),'cell.count']
dat2 <- dat2[,!colnames(dat2) %in% c('file.name','path')]
d <- dat2
d <- d[order(d$uid,d$image.time),]
d$time <- 0
d$time <- unlist(lapply(unique(d$uid), function(id) signif(difftime(d[d$uid==id,'image.time'],d[d$uid==id,'image.time'][1],units='hours'),3)))
d$uid2 <- NULL
rownames(d) <- NULL
#Save file
write.csv(d,file=paste0(fp),row.names=FALSE)
####
# Try to add platemap info
####
# plate map paths
mappaths <- file.path(datadirs,list.files(datadirs)[grep('platemap',list.files(datadirs))])
expt_id <- sapply(datadirs, function(x) basename(x))
mappaths
datadirs
source('~/Repos/misc/Segmentation/R/gatherCVcounts.r', echo=TRUE)
####
# Try to add platemap info
####
# plate map paths
mappaths <- file.path(datadirs,list.files(datadirs)[grep('platemap',list.files(datadirs))])
expt_id <- sapply(datadirs, function(x) basename(x))
ad <- do.call(rbind,lapply(expt_id, function(id)
{
dat <- d[d$expt.id==id,]
addMapInfo(dat,mappaths[grep(id,mappaths)])
}))
ad$upid <- ad$expt.id
ad$uid <- NULL
ad
if (sum(!is.na(ad$cell.line)) != sum(!is.na(ad$drug1))){
message('Check plate map.  There are conditions without cell lines or vice versa')
}
if (sum(is.na(ad$cell.line))>0){
message('Removing imaged wells with no annotation')
ad = ad[!is.na(ad$cell.line),]
}
#write resulting file
write.csv(ad,file=paste0(topdir,'/all_cell_counts_annotated.csv'),row.names=FALSE)
install.packages("devtools")
library(devtools)
install_github("Vivianstats/scImpute")
library(devtools)
#install_github("Vivianstats/scImpute")
setwd('~/Desktop/Parthenon_Pancreas_project/scbeta_indrops/05_Figures/isolated_pop_data_for_imputation-SCIMPUTE/')
library(scImpute)
fil = 'x1_S3c_pdx1.csv'
strsplit(fil,'.')
strsplit(fil,".")
fil = "x1_S3c_pdx1.csv"
strsplit(fil,".")
fil
fil<-"x1_S3c_pdx1.csv"
fil
strsplit(fil,".csv")
strsplit(fil,".csv")[1]
strsplit(fil,".csv")[1][1]
paste0('./scimpute-ouput_',strsplit(fil,".csv")[1],'/')
